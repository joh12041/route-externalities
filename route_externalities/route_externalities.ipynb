{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Route-Level Externalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Parameters etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "from math import floor\n",
    "\n",
    "import numpy as np\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "EXPECTED_HEADER = ['ID', 'name', 'polyline_points', 'total_time_in_sec', 'total_distance_in_meters',\n",
    "                   'number_of_steps', 'maneuvers', 'beauty', 'simplicity', 'pctNonHighwayTime',\n",
    "                   'pctNonHighwayDist', 'pctNeiTime', 'pctNeiDist']\n",
    "METRICS = ['time_min', 'dist_km', 'nsteps', 'nsteps_per_km', 'nlefts', 'simplicity', 'beauty',\n",
    "           'pctNHT', 'pctNHD', 'pctSNT', 'pctSND']\n",
    "OUTPUT_HEADER = ['filename', 'dist', 'bin', 'num_entries']\n",
    "for metric in METRICS:\n",
    "    OUTPUT_HEADER.extend(['LB_{0}'.format(metric), 'avg_{0}'.format(metric), 'UB_{0}'.format(metric)])\n",
    "FOLDER = \"../data/final/impacts\"\n",
    "CITIES = [\"lon\", \"man\", \"sf\", \"nyc\"]\n",
    "TYPES = [\"rand\", \"taxi\"]\n",
    "\n",
    "FNS = [\"gh_routes_beauty.csv\", \"gh_routes_fast.csv\", \"gh_routes_simple.csv\", \"gh_routes_safety.csv\",\n",
    "       \"google_traffic_routes_main_ghmerged.csv\", \"mapquest_traffic_routes_main_ghmerged.csv\"]\n",
    "\n",
    "id_idx = EXPECTED_HEADER.index(\"ID\")\n",
    "name_idx = EXPECTED_HEADER.index(\"name\")\n",
    "time_idx = EXPECTED_HEADER.index(\"total_time_in_sec\")\n",
    "dist_idx = EXPECTED_HEADER.index(\"total_distance_in_meters\")\n",
    "step_idx = EXPECTED_HEADER.index(\"number_of_steps\")\n",
    "man_idx = EXPECTED_HEADER.index(\"maneuvers\")\n",
    "sim_idx = EXPECTED_HEADER.index(\"simplicity\")\n",
    "bty_idx = EXPECTED_HEADER.index(\"beauty\")\n",
    "pctNHT_idx = EXPECTED_HEADER.index(\"pctNonHighwayTime\")\n",
    "pctNHD_idx = EXPECTED_HEADER.index(\"pctNonHighwayDist\")\n",
    "pctSND_idx = EXPECTED_HEADER.index(\"pctNeiDist\")\n",
    "pctSNT_idx = EXPECTED_HEADER.index(\"pctNeiTime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for bootstrap resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def resample_vals(values):\n",
    "    numvals = len(values)\n",
    "    newvals = []\n",
    "    for i in range(0, numvals):\n",
    "        randidx = randint(0, numvals-1)\n",
    "        newvals.append(values[randidx])\n",
    "    return newvals\n",
    "    \n",
    "\n",
    "def bootstrap_interval(values, numiter=10000, alpha=0.01):\n",
    "    avg_vals = []\n",
    "    for i in range(0, numiter):\n",
    "        newvals = resample_vals(values)\n",
    "        avg_vals.append(np.mean(newvals))\n",
    "    sorted_vals = sorted(avg_vals)\n",
    "    return {'LB' : sorted_vals[int(numiter * (alpha / 2))],\n",
    "            'avg' : sorted_vals[int(numiter * 0.5)],\n",
    "            'UB' : sorted_vals[int(numiter * (1 - (alpha / 2)))]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core class for holding and computing statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RouteStats(object):\n",
    "    \n",
    "    def __init__(self, folder, city, routetype, fns, writeoutput):\n",
    "        self.city = city\n",
    "        self.input_csvs = [\"{0}/{1}_{2}_{3}\".format(folder, city, routetype, fn) for fn in fns]\n",
    "        self.output_csv = \"{0}/{1}_{2}_stats.csv\".format(folder, city, routetype)\n",
    "        for i in range(len(self.input_csvs) - 1, -1, -1):\n",
    "            if not os.path.exists(self.input_csvs[i]):\n",
    "                 print(\"{0} does not exist.\".format(self.input_csvs.pop(i)))\n",
    "        self.stats = {}\n",
    "        self.dist_bins = []\n",
    "        self.bin_step = 1\n",
    "        self.highest_bin = 1\n",
    "        self.straight_line_distances = {}\n",
    "        self.route_ids = {}\n",
    "        self.writeoutput = writeoutput\n",
    "        self.label = '{0}|{1}'.format(city, routetype)\n",
    "        \n",
    "    def compute_stats(self):\n",
    "        # check if valid inputs and set some parameters\n",
    "        if not self.prepared():\n",
    "            return\n",
    "\n",
    "        # build necessary dictionaries\n",
    "        self.get_straight_line_distances()\n",
    "        self.get_route_ids()\n",
    "        self.initialize_stats()\n",
    "        \n",
    "        print(\"Analyzing {0}. Output to {1}\".format(self.city, self.output_csv))\n",
    "\n",
    "        errors = 0\n",
    "        processed = 0\n",
    "        for fn in self.input_csvs:\n",
    "            with open(fn, 'r') as fin:\n",
    "                csvreader = csv.reader(fin)\n",
    "                assert next(csvreader)[:len(EXPECTED_HEADER)] == EXPECTED_HEADER\n",
    "                for line in csvreader:\n",
    "                    if line[id_idx] not in self.route_ids:\n",
    "                        continue\n",
    "                    try:\n",
    "                        name = line[name_idx]\n",
    "                        time_min = float(line[time_idx]) / 60\n",
    "                        dist_km = float(line[dist_idx]) / 1000\n",
    "                        nlefts = line[man_idx].count('left')\n",
    "                        nsteps = float(line[step_idx])\n",
    "                        if 'exit transit' or 'finish' in line[man_idx]:\n",
    "                            nsteps = nsteps - 1\n",
    "                        nsteps = nsteps - line[man_idx].count('continue')\n",
    "                        nsteps_per_km = nsteps / dist_km\n",
    "                        simplicity = float(line[sim_idx])\n",
    "                        beauty = float(line[bty_idx])\n",
    "                        pctNHT = float(line[pctNHT_idx])\n",
    "                        pctNHD = float(line[pctNHD_idx])\n",
    "                        pctSNT = float(line[pctSNT_idx])\n",
    "                        pctSND = float(line[pctSND_idx])\n",
    "                        dist_bin = self.straight_line_distances[line[id_idx]]\n",
    "                        self.stats[fn][dist_bin]['avg_time_min'].append(time_min)\n",
    "                        self.stats[fn][dist_bin]['avg_dist_km'].append(dist_km)\n",
    "                        self.stats[fn][dist_bin]['avg_nsteps'].append(nsteps)\n",
    "                        self.stats[fn][dist_bin]['avg_nlefts'].append(nlefts)\n",
    "                        self.stats[fn][dist_bin]['avg_simplicity'].append(simplicity)\n",
    "                        self.stats[fn][dist_bin]['avg_beauty'].append(beauty)\n",
    "                        self.stats[fn][dist_bin]['avg_pctNHT'].append(pctNHT)\n",
    "                        self.stats[fn][dist_bin]['avg_pctNHD'].append(pctNHD)\n",
    "                        self.stats[fn][dist_bin]['avg_pctSNT'].append(pctSNT)\n",
    "                        self.stats[fn][dist_bin]['avg_pctSND'].append(pctSND)\n",
    "                        processed += 1\n",
    "                    except (ValueError, ZeroDivisionError, KeyError):\n",
    "                        errors += 1\n",
    "                        continue\n",
    "\n",
    "            self.process_stats(fn)\n",
    "        print(\"{0} errors in processing (and thus lines skipped). {1} kept.\".format(errors, processed))\n",
    "        self.update_names()\n",
    "\n",
    "        # write statistics for each file to an output CSV\n",
    "        if self.writeoutput:\n",
    "            with open(self.output_csv, 'w') as fout:\n",
    "                csvwriter = csv.DictWriter(fout, fieldnames=OUTPUT_HEADER)\n",
    "                csvwriter.writeheader()\n",
    "                for dist_bin in self.dist_bins:        \n",
    "                    for fn in self.input_csvs:\n",
    "                        if self.stats[fn][dist_bin]['num_entries'] > 0:\n",
    "                            csvwriter.writerow(self.stats[fn][dist_bin])\n",
    "\n",
    "\n",
    "\n",
    "                                \n",
    "    def update_names(self):\n",
    "        \"\"\"More readable names for Plotly\"\"\"\n",
    "        for dist_bin in self.dist_bins:\n",
    "            for fn in self.input_csvs:\n",
    "                if 'google' in fn:\n",
    "                    platform = 'Google'\n",
    "                elif 'mapquest' in fn:\n",
    "                    platform = 'MapQst'\n",
    "                elif 'gh' in fn:\n",
    "                    platform = 'GraphH'\n",
    "                else:\n",
    "                    platform = \"\"\n",
    "                    print(\"Don't recognize this filename: {0}\".format(filename))\n",
    "\n",
    "                if 'fast' in fn or 'main' in fn:\n",
    "                    routetype = \"Fastest\"\n",
    "                elif 'beaut' in fn:\n",
    "                    routetype = \"Beautfl\"\n",
    "                elif 'simple' in fn:\n",
    "                    routetype = \"Simplst\"\n",
    "                elif 'saf' in fn:\n",
    "                    routetype = \"Safest\"\n",
    "                else:\n",
    "                    routetype = \"\"\n",
    "                    print(\"Don't recognize a route type: {0}\".format(filename))\n",
    "\n",
    "                if 'notraffic' in fn:\n",
    "                    conditions = \"(No Traffic)\"\n",
    "                elif 'traffic' in fn:\n",
    "                    conditions = \"(Traffic)\"\n",
    "                else:\n",
    "                    conditions = \"\"\n",
    "                self.stats[fn][dist_bin]['filename'] = \"{0}-{1} {2}\".format(platform, routetype, conditions)\n",
    "        \n",
    "        \n",
    "    def process_stats(self, fn):\n",
    "        \"\"\"Calculate bootstrapped averages and confidence intervals for each stat, distance, and set of routes.\"\"\"\n",
    "        print(\"Bootstrapping CIs for {0}\".format(fn))\n",
    "        for dist_bin in self.dist_bins:\n",
    "            label = fn\n",
    "            num_entries = len(self.stats[label][dist_bin]['avg_time_min'])\n",
    "            self.stats[label][dist_bin]['num_entries'] = num_entries\n",
    "            if num_entries:\n",
    "                for metric in METRICS:\n",
    "                    bootstrapped_interval = bootstrap_interval(self.stats[label][dist_bin]['avg_{0}'.format(metric)],\n",
    "                                                               numiter=1000, alpha=0.01)\n",
    "                    self.stats[label][dist_bin]['LB_{0}'.format(metric)] = bootstrapped_interval['LB']\n",
    "                    self.stats[label][dist_bin]['avg_{0}'.format(metric)] = bootstrapped_interval['avg']\n",
    "                    self.stats[label][dist_bin]['UB_{0}'.format(metric)] = bootstrapped_interval['UB']\n",
    "                \n",
    "\n",
    "\n",
    "    def initialize_stats(self):\n",
    "        \"\"\"Initialize data structures for statistics for each distance bin.\"\"\"\n",
    "        stats_start_idx = OUTPUT_HEADER.index(\"num_entries\")\n",
    "        for fn in self.input_csvs:\n",
    "            self.stats[fn] = {}\n",
    "            for dist in self.dist_bins:\n",
    "                self.stats[fn][dist] = {'dist':'{0}-{1} km'.format(dist, dist + self.bin_step), 'filename':fn, 'bin':dist+self.bin_step}\n",
    "                for stat in OUTPUT_HEADER[stats_start_idx:]:\n",
    "                    self.stats[fn][dist][stat] = []\n",
    "            self.stats[fn][self.dist_bins[-1]]['dist'] = '>{0} km'.format(self.dist_bins[-1])\n",
    "\n",
    "\n",
    "\n",
    "    def get_route_ids(self):\n",
    "        \"\"\"Go through all route IDs and only keep the od-pairs that appear in all files.\"\"\"\n",
    "        for fn in self.input_csvs:\n",
    "            with open(fn, 'r') as fin:\n",
    "                csvreader = csv.reader(fin)\n",
    "                assert next(csvreader)[:len(EXPECTED_HEADER)] == EXPECTED_HEADER, \"{0}: {1}\".format(fn, EXPECTED_HEADER)\n",
    "                for line in csvreader:\n",
    "                    try:\n",
    "                        if float(line[dist_idx]) <= 0:\n",
    "                            continue\n",
    "                        route_id = line[id_idx]\n",
    "                        self.route_ids[route_id] = self.route_ids.get(route_id, 0) + 1\n",
    "                    except IndexError:\n",
    "                        print(\"{0}: Skipping {1} {2}\".format(fn, len(line), line[0]))\n",
    "                        continue\n",
    "\n",
    "        id_list = list(self.route_ids.keys())\n",
    "        num_files = len(self.input_csvs)\n",
    "        original_num_ids = len(self.route_ids)\n",
    "        for route_id in id_list:\n",
    "            if self.route_ids[route_id] != num_files:\n",
    "                self.route_ids.pop(route_id)\n",
    "\n",
    "        print(\"{0} IDs appear in all files and were kept out of {1}.\".format(len(self.route_ids), original_num_ids))\n",
    "\n",
    "    def prepared(self):\n",
    "        \"\"\"Prepare data structures if necessary.\"\"\"\n",
    "        if len(self.input_csvs) == 0:\n",
    "            print(\"No input CSVs.\")\n",
    "            return False\n",
    "\n",
    "        self.set_parameters()\n",
    "        return True\n",
    "\n",
    "    def set_parameters(self):\n",
    "        \"\"\"Set cap to distance bins for analysis.\"\"\"\n",
    "        if self.city == \"nyc\":\n",
    "            self.highest_bin = 27\n",
    "        elif self.city == \"sf\":\n",
    "            self.highest_bin = 13\n",
    "        else:\n",
    "            self.highest_bin = 30\n",
    "        self.dist_bins = [i for i in range(0, self.highest_bin + 1, self.bin_step)]\n",
    "\n",
    "\n",
    "    def get_straight_line_distances(self):\n",
    "        \"\"\"Assign each od-pair to a distance bin based on Euclidean distance.\"\"\"\n",
    "        if 'nyc_' in self.input_csvs[0]:\n",
    "            if 'taxi' in self.input_csvs[0]:\n",
    "                fn = \"../data/intermediate/nyc_taxi_od_pairs.csv\"\n",
    "            else:\n",
    "                fn = \"../data/intermediate/nyc_rand_od_pairs.csv\"\n",
    "        elif 'sf_' in self.input_csvs[0]:\n",
    "            if 'taxi' in self.input_csvs[0]:\n",
    "                fn = \"../data/intermediate/sf_taxi_od_pairs.csv\"\n",
    "            else:\n",
    "                fn = \"../data/intermediate/sf_rand_od_pairs.csv\"\n",
    "        elif 'lon_' in self.input_csvs[0]:\n",
    "            fn = \"../data/intermediate/lon_rand_od_pairs.csv\"\n",
    "        elif 'man_' in self.input_csvs[0]:\n",
    "            fn = \"../data/intermediate/man_rand_od_pairs.csv\"\n",
    "        else:\n",
    "            print(\"City not detected.\")\n",
    "            return\n",
    "\n",
    "        with open(fn, 'r') as fin:\n",
    "            csvreader = csv.reader(fin)\n",
    "            header = next(csvreader)\n",
    "            straight_line_idx = header.index(\"straight_line_distance\")\n",
    "            for line in csvreader:\n",
    "                dist = float(line[straight_line_idx])\n",
    "                dist_bin = floor(dist / self.bin_step) * self.bin_step\n",
    "                if dist_bin >= self.dist_bins[-1]:\n",
    "                        dist_bin = self.dist_bins[-1]\n",
    "                self.straight_line_distances[line[id_idx]] = dist_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down to business - compute stats for each city and set of od pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statsobjs = []\n",
    "for city in CITIES:\n",
    "    for routetype in TYPES:\n",
    "        statsobj = RouteStats(FOLDER, city, routetype, FNS, True)\n",
    "        try:\n",
    "            statsobj.compute_stats()\n",
    "            statsobjs.append(statsobj)\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "            print(\"Skipping: {0}, {1}, {2}\".format(FOLDER, city, routetype))\n",
    "            continue\n",
    "\n",
    "for i in range(len(statsobjs) - 1, -1, -1):\n",
    "    st = statsobjs[i]\n",
    "    if len(st.route_ids) == 0:\n",
    "        statsobjs.pop(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional - save output to avoid redoing bootstrapping in future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_fn = \"statsobjs_routeexternalities.pkl\"\n",
    "\n",
    "# Write out current stats objects:\n",
    "pickle.dump(statsobjs, open(pickle_fn, 'wb'))\n",
    "\n",
    "# Read in previous stats objects:\n",
    "#with open(pickle_fn, \"rb\") as fin:\n",
    "#    statsobjs = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Random and Taxi routes in NYC and SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ylabs = ['avg_nsteps', 'avg_nsteps', 'avg_nsteps_per_km', 'avg_beauty', 'avg_pctNHT', 'avg_pctSNT', 'avg_time_min']\n",
    "pres_ylabs = [\"Avg # Turns\", \"Avg # Turns\", \"Avg # Turns<br>per km\", \"Avg Beauty\", \"Avg Proportion<br>Time on Highways\", \"Avg Proportion Time<br>in Small Neighborhoods\", \"Avg Time (min)\"]\n",
    "pres_city = {'lon':'London', 'man':\"Manila\", \"nyc\":\"New York City\", \"sf\":\"San Francisco\"}\n",
    "\n",
    "for i in range(0, len(pres_ylabs)):\n",
    "    if i in [1,3]:\n",
    "        pres_ylabs[i] = pres_ylabs[i] + \"<br>(Normalized)\"\n",
    "    pres_ylabs[i] = \"<b>{0}</b>\".format(pres_ylabs[i])\n",
    "\n",
    "colors = {'GraphH-Beautfl ' : 'rgb(12,44,132)',\n",
    "          'GraphH-Simplst ' : 'rgb(34,94,168)',\n",
    "          'GraphH-Fastest ' : 'rgb(65,182,196)',\n",
    "          'GraphH-Safest '   : 'rgb(29,145,192)',\n",
    "          'Google-Fastest (Traffic)' : 'rgb(254,178,76)',\n",
    "          'MapQst-Fastest (Traffic)' : 'rgb(254,217,118)'}\n",
    "\n",
    "cities = ['sf', 'nyc'] #, 'lon', 'man']\n",
    "titles = ['<b>{0}</b>'.format(pres_city[st.city]) for st in statsobjs if 'taxi' not in st.output_csv and st.city in cities]\n",
    "\n",
    "fig = plotly.tools.make_subplots(rows=len(ylabs), cols=len(titles), subplot_titles=(titles * 1), shared_yaxes=True, shared_xaxes=True, vertical_spacing=0.035)\n",
    "fig['layout'].update(height=len(ylabs)*640, width=len(titles)*800, showlegend=False, font={'family' : 'Droid Sans', 'size' : 16})\n",
    "for i in range(0, len(ylabs)):\n",
    "    traces = {}\n",
    "    do_normalize = False\n",
    "    if 'Normalized' in pres_ylabs[i]:\n",
    "        do_normalize = True\n",
    "    for statsobj in statsobjs:\n",
    "        if statsobj.city not in cities:\n",
    "            continue\n",
    "        if 'rand' in statsobj.output_csv:\n",
    "            rt = \"rand\"\n",
    "        elif 'taxi' in statsobj.output_csv:\n",
    "            rt = \"taxi\"\n",
    "        traces[statsobj.label] = []\n",
    "        for fn in statsobj.input_csvs:\n",
    "            if ylabs[i] == 'avg_time_min' and ('google' in fn or 'mapquest' in fn):\n",
    "                continue\n",
    "            xvals = []\n",
    "            yvals = []\n",
    "            yvals_lb = []\n",
    "            yvals_ub = []\n",
    "            desc = \"\"\n",
    "            for dist_bin in statsobj.dist_bins:\n",
    "                normalize = 1\n",
    "                if do_normalize and ylabs[i] == 'avg_dist_km':\n",
    "                    #normalize = 1\n",
    "                    #normalize = statsobj.stats['{0}/{1}_{2}_{3}.csv'.format(FOLDER, statsobj.city, TYPES[0], 'gh_routes_shortest')][dist_bin][ylabs[i]]\n",
    "                    normalize = statsobj.stats['{0}/{1}_{2}_{3}.csv'.format(FOLDER, statsobj.city, rt, 'gh_routes_fast')][dist_bin][ylabs[i]]\n",
    "                elif do_normalize and ylabs[i] == 'avg_time_min':\n",
    "                    #normalize = 1\n",
    "                    normalize = statsobj.stats['{0}/{1}_{2}_{3}.csv'.format(FOLDER, statsobj.city, rt, 'gh_routes_fast')][dist_bin][ylabs[i]]\n",
    "                elif do_normalize and (ylabs[i] == 'avg_simplicity' or ylabs[i] == 'avg_nlefts' or ylabs[i] == 'avg_nsteps'):\n",
    "                    normalize = statsobj.stats['{0}/{1}_{2}_{3}.csv'.format(FOLDER, statsobj.city, rt, 'gh_routes_simple')][dist_bin][ylabs[i]]\n",
    "                elif do_normalize and ylabs[i] == 'avg_beauty':\n",
    "                    normalize = statsobj.stats['{0}/{1}_{2}_{3}.csv'.format(FOLDER, statsobj.city, rt, 'gh_routes_beauty')][dist_bin][ylabs[i]]\n",
    "                if statsobj.stats[fn][dist_bin]['num_entries'] > 0:\n",
    "                    xvals.append(dist_bin)\n",
    "                    avg = statsobj.stats[fn][dist_bin][ylabs[i]] / normalize\n",
    "                    lb = avg - (statsobj.stats[fn][dist_bin][ylabs[i].replace(\"avg_\", \"LB_\")] / normalize)\n",
    "                    ub = (statsobj.stats[fn][dist_bin][ylabs[i].replace(\"avg_\", \"UB_\")] / normalize) - avg\n",
    "                    if ylabs[i] == 'avg_pctNHT' or ylabs[i] == 'avg_pctNHD':\n",
    "                        avg = 1 - avg\n",
    "                        lb = 1 - ub\n",
    "                        ub = 1 - lb\n",
    "                    yvals.append(avg)\n",
    "                    # TODO: figure out how to compute this correctly at the bootstrap step and not at this already aggregated step\n",
    "                    yvals_lb.append(lb)\n",
    "                    yvals_ub.append(ub)\n",
    "                    desc = \"{0}|{1}\".format(statsobj.label, statsobj.stats[fn][dist_bin]['filename'])  # lots of overwriting, but simplest method\n",
    "                    \n",
    "            if xvals:\n",
    "                trace = plotly.graph_objs.Scatter(x=xvals,\n",
    "                                                  y=yvals,\n",
    "                                                  name=desc,\n",
    "                                                  mode='lines',\n",
    "                                                  line={'color':colors[desc.split(\"|\")[2]], 'width':2},\n",
    "                                                  error_y={'type' : \"data\",\n",
    "                                                           'array' : yvals_ub,\n",
    "                                                           'arrayminus' : yvals_lb,\n",
    "                                                           'color':colors[desc.split(\"|\")[2]],\n",
    "                                                           'width':0.5,\n",
    "                                                           'visible' : True,\n",
    "                                                           'symmetric' : True})\n",
    "                traces[statsobj.label].append(trace)\n",
    "                \n",
    "    in_line_with_plotly = 1\n",
    "    for j in range(0, len(statsobjs)):\n",
    "        if traces.get(statsobjs[j].label, False):# and 'rand' not in statsobjs[j].output_csv:\n",
    "            for trace in traces[statsobjs[j].label]:\n",
    "                if statsobjs[j].city == \"sf\":\n",
    "                    fig.append_trace(trace, i+1, 1)\n",
    "                else:\n",
    "                    fig.append_trace(trace, i+1, 2)\n",
    "                #fig.append_trace(trace, i+1, j+in_line_with_plotly)\n",
    "        else:\n",
    "            in_line_with_plotly = in_line_with_plotly - 1\n",
    "    fig['layout']['yaxis{0}'.format(i+1)].update(title=pres_ylabs[i])\n",
    "    #fig['layout']['yaxis{0}'.format(i+1)]['titlefont'].update(size=24, family=\"Droid Sans\")\n",
    "    fig['layout']['yaxis{0}'.format(i+1)]['domain'][0] = max(0, fig['layout']['yaxis{0}'.format(i+1)]['domain'][0])\n",
    "\n",
    "for j in range(0, len(titles)):\n",
    "    fig['layout']['xaxis{0}'.format(j+1)].update(title=\"\")\n",
    "    #fig['layout']['xaxis{0}'.format(j+1)]['titlefont'].update(size=24, family=\"Droid Sans\")\n",
    "fig['layout']['xaxis{0}'.format(3)].update(title=\"<b>Straight-Line Distance (km)</b>\")\n",
    "for ann in fig['layout']['annotations']:\n",
    "    ann['font'] = {'size':16, 'family':'Droid Sans'}\n",
    "plotly.offline.iplot(fig, show_link=False, image=\"png\", image_height=1400, image_width=1600, filename=\"impacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare route-level externalities for random od-pairs across all cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ylabs = ['avg_nsteps', 'avg_nsteps', 'avg_nsteps_per_km', 'avg_beauty', 'avg_pctNHT', 'avg_pctSNT', 'avg_time_min']\n",
    "pres_ylabs = [\"Avg # Turns\", \"Avg # Turns\", \"Avg # Turns<br>per km\", \"Avg Beauty\", \"Avg Proportion<br>Time on Highways\", \"Avg Proportion Time<br>in Small Neighborhoods\", \"Avg Time (min)\"]\n",
    "pres_city = {'lon':'London', 'man':\"Manila\", \"sin\":\"Singapore\", \"nyc\":\"New York City\", \"sf\":\"San Francisco\"}\n",
    "\n",
    "for i in range(0, len(pres_ylabs)):\n",
    "    if i in [1,3]:\n",
    "        pres_ylabs[i] = pres_ylabs[i] + \"<br>(Normalized)\"\n",
    "    pres_ylabs[i] = \"<b>{0}</b>\".format(pres_ylabs[i])\n",
    "\n",
    "colors = {'GraphH-Beautfl ' : 'rgb(12,44,132)',\n",
    "          'GraphH-Simplst ' : 'rgb(34,94,168)',\n",
    "          'GraphH-Fastest ' : 'rgb(65,182,196)',\n",
    "          'GraphH-Safest '   : 'rgb(29,145,192)',\n",
    "          'Google-Fastest (Traffic)' : 'rgb(254,178,76)',\n",
    "          'MapQst-Fastest (Traffic)' : 'rgb(254,217,118)'}\n",
    "\n",
    "cities = ['sf', 'nyc', 'lon', 'man']\n",
    "titles = ['<b>{0}</b>'.format(pres_city[st.city]) for st in statsobjs if 'taxi' not in st.output_csv and st.city in cities]\n",
    "\n",
    "fig = plotly.tools.make_subplots(rows=len(ylabs), cols=len(titles), subplot_titles=(titles * 1), shared_yaxes=True, shared_xaxes=True, vertical_spacing=0.035)\n",
    "fig['layout'].update(height=len(ylabs)*480, width=len(titles)*600, showlegend=False, font={'family' : 'Droid Sans', 'size' : 16})\n",
    "for i in range(0, len(ylabs)):\n",
    "    traces = {}\n",
    "    do_normalize = False\n",
    "    if 'Normalized' in pres_ylabs[i]:\n",
    "        do_normalize = True\n",
    "    for statsobj in statsobjs:\n",
    "        if 'rand' in statsobj.output_csv or statsobj.city not in cities:\n",
    "            continue\n",
    "        traces[statsobj.label] = []\n",
    "        for fn in statsobj.input_csvs:\n",
    "            if ylabs[i] == 'avg_time_min' and ('google' in fn or 'mapquest' in fn):\n",
    "                continue\n",
    "            xvals = []\n",
    "            yvals = []\n",
    "            yvals_lb = []\n",
    "            yvals_ub = []\n",
    "            desc = \"\"\n",
    "            for dist_bin in statsobj.dist_bins:\n",
    "                normalize = 1\n",
    "                if do_normalize and ylabs[i] == 'avg_dist_km':\n",
    "                    #normalize = 1\n",
    "                    #normalize = statsobj.stats['{0}/{1}_{2}_{3}.csv'.format(FOLDER, statsobj.city, TYPES[0], 'gh_routes_shortest')][dist_bin][ylabs[i]]\n",
    "                    normalize = statsobj.stats['{0}/{1}_{2}_{3}.csv'.format(FOLDER, statsobj.city, \"grid\", 'gh_routes_fast')][dist_bin][ylabs[i]]\n",
    "                elif do_normalize and ylabs[i] == 'avg_time_min':\n",
    "                    #normalize = 1\n",
    "                    normalize = statsobj.stats['{0}/{1}_{2}_{3}.csv'.format(FOLDER, statsobj.city, \"grid\", 'gh_routes_fast')][dist_bin][ylabs[i]]\n",
    "                elif do_normalize and (ylabs[i] == 'avg_simplicity' or ylabs[i] == 'avg_nlefts' or ylabs[i] == 'avg_nsteps'):\n",
    "                    normalize = statsobj.stats['{0}/{1}_{2}_{3}.csv'.format(FOLDER, statsobj.city, \"grid\", 'gh_routes_simple')][dist_bin][ylabs[i]]\n",
    "                elif do_normalize and ylabs[i] == 'avg_beauty':\n",
    "                    normalize = statsobj.stats['{0}/{1}_{2}_{3}.csv'.format(FOLDER, statsobj.city, \"grid\", 'gh_routes_beauty')][dist_bin][ylabs[i]]\n",
    "                if statsobj.stats[fn][dist_bin]['num_entries'] > 0:\n",
    "                    xvals.append(dist_bin)\n",
    "                    avg = statsobj.stats[fn][dist_bin][ylabs[i]] / normalize\n",
    "                    lb = avg - (statsobj.stats[fn][dist_bin][ylabs[i].replace(\"avg_\", \"LB_\")] / normalize)\n",
    "                    ub = (statsobj.stats[fn][dist_bin][ylabs[i].replace(\"avg_\", \"UB_\")] / normalize) - avg\n",
    "                    if ylabs[i] == 'avg_pctNHT' or ylabs[i] == 'avg_pctNHD':\n",
    "                        avg = 1 - avg\n",
    "                        lb = 1 - ub\n",
    "                        ub = 1 - lb\n",
    "                    yvals.append(avg)\n",
    "                    # TODO: figure out how to compute this correctly at the bootstrap step and not at this already aggregated step\n",
    "                    yvals_lb.append(lb)\n",
    "                    yvals_ub.append(ub)\n",
    "                    desc = statsobj.stats[fn][dist_bin]['filename']  # lots of overwriting, but simplest method\n",
    "                    \n",
    "            if xvals:\n",
    "                trace = plotly.graph_objs.Scatter(x=xvals,\n",
    "                                                  y=yvals,\n",
    "                                                  name=desc,\n",
    "                                                  mode='lines',\n",
    "                                                  line={'color':colors[desc]},\n",
    "                                                  error_y={'type' : \"data\",\n",
    "                                                           'array' : yvals_ub,\n",
    "                                                           'arrayminus' : yvals_lb,\n",
    "                                                           'color':colors[desc],\n",
    "                                                           'width':0.5,\n",
    "                                                           'visible' : True,\n",
    "                                                           'symmetric' : True})\n",
    "                traces[statsobj.label].append(trace)\n",
    "                \n",
    "    in_line_with_plotly = 1\n",
    "    for j in range(0, len(statsobjs)):\n",
    "        if traces.get(statsobjs[j].label, False) and 'rand' not in statsobjs[j].output_csv:\n",
    "            for trace in traces[statsobjs[j].label]:\n",
    "                fig.append_trace(trace, i+1, j+in_line_with_plotly)\n",
    "        else:\n",
    "            in_line_with_plotly = in_line_with_plotly - 1\n",
    "    fig['layout']['yaxis{0}'.format(i+1)].update(title=pres_ylabs[i])\n",
    "    #fig['layout']['yaxis{0}'.format(i+1)]['titlefont'].update(size=24, family=\"Droid Sans\")\n",
    "    fig['layout']['yaxis{0}'.format(i+1)]['domain'][0] = max(0, fig['layout']['yaxis{0}'.format(i+1)]['domain'][0])\n",
    "\n",
    "for j in range(0, len(titles)):\n",
    "    fig['layout']['xaxis{0}'.format(j+1)].update(title=\"\")\n",
    "    #fig['layout']['xaxis{0}'.format(j+1)]['titlefont'].update(size=24, family=\"Droid Sans\")\n",
    "fig['layout']['xaxis{0}'.format(3)].update(title=\"<b>Straight-Line Distance (km)</b>\")\n",
    "for ann in fig['layout']['annotations']:\n",
    "    ann['font'] = {'size':16, 'family':'Droid Sans'}\n",
    "plotly.offline.iplot(fig, show_link=False, image=\"png\", image_height=1600, image_width=1600, filename=\"impacts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
